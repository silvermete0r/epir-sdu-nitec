{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# No words, just work => Goal: TOP #1 🍋\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Data Visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nsns.set_theme(style='whitegrid', palette='viridis')\n\n# Natural Language Processing | Machine Learning models\nimport spacy\nimport string\nimport gensim\nimport operator\nimport re\nfrom tqdm import tqdm\n\n# Ignore any warnings: chill..\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-15T04:05:45.985954Z","iopub.status.idle":"2023-10-15T04:05:45.986477Z","shell.execute_reply.started":"2023-10-15T04:05:45.986218Z","shell.execute_reply":"2023-10-15T04:05:45.986242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/nitec-epir-dataset/epir_train/articles.csv')\ndf_test = pd.read_csv('/kaggle/input/nitec-epir-dataset/epir_test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:45.987584Z","iopub.status.idle":"2023-10-15T04:05:45.988084Z","shell.execute_reply.started":"2023-10-15T04:05:45.987821Z","shell.execute_reply":"2023-10-15T04:05:45.987843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df_train[df_train['sys_lang'].isin(['en', 'ru', 'qq', 'kk'])]))\nprint('Kazakh:', len(df_train[df_train['sys_lang'] == 'kk']))\nprint('Kazakh(Latin):', len(df_train[df_train['sys_lang'] == 'qq']))\nprint('Russian:', len(df_train[df_train['sys_lang'] == 'ru']))\nprint('English:', len(df_train[df_train['sys_lang'] == 'en']))","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:45.989565Z","iopub.status.idle":"2023-10-15T04:05:45.990180Z","shell.execute_reply.started":"2023-10-15T04:05:45.989810Z","shell.execute_reply":"2023-10-15T04:05:45.989833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:45.991775Z","iopub.status.idle":"2023-10-15T04:05:45.992296Z","shell.execute_reply.started":"2023-10-15T04:05:45.992024Z","shell.execute_reply":"2023-10-15T04:05:45.992048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Datasets\ndf_articles = pd.read_csv('/kaggle/input/nitec-epir-dataset/epir_train/articles.csv')\ndf_lifes = pd.read_csv('/kaggle/input/nitec-epir-dataset/epir_train/life_situations.csv')\ndf_news = pd.read_csv('/kaggle/input/nitec-epir-dataset/epir_train/news.csv')\ndf_services = pd.read_csv('/kaggle/input/nitec-epir-dataset/epir_train/services.csv')\n\n# Testing Datasets\ndf_test = pd.read_csv('/kaggle/input/nitec-epir-dataset/epir_test.csv')\ndf_subsample = pd.read_csv('/kaggle/input/nitec-epir-dataset/epir_sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:45.993951Z","iopub.status.idle":"2023-10-15T04:05:45.994463Z","shell.execute_reply.started":"2023-10-15T04:05:45.994209Z","shell.execute_reply":"2023-10-15T04:05:45.994233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_lifes.drop(columns=['subid'], inplace=True)\ndf_lifes.rename(columns={'URL': 'url'}, inplace=True)\n\ndef df_generalize(df, category):\n    if 'content' in df.columns:\n        df.rename(columns={'content': 'x'}, inplace=True)\n    drop_columns = df.columns[3:-1]\n    df['content'] = df.iloc[:, 3:-1].apply(lambda row: ' '.join(map(str, row)), axis=1)\n    df.drop(columns=drop_columns, inplace=True)\n    df.drop(['id'], axis=1, inplace=True)\n    df.rename(columns={'Unnamed: 0': 'id'}, inplace=True)\n    df = df.assign(**{'category': category})\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:45.995615Z","iopub.status.idle":"2023-10-15T04:05:45.996103Z","shell.execute_reply.started":"2023-10-15T04:05:45.995848Z","shell.execute_reply":"2023-10-15T04:05:45.995870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_news = df_generalize(df_news, 'news')\ndf_lifes = df_generalize(df_lifes, 'lifes')\ndf_articles = df_generalize(df_articles, 'articles')\ndf_services = df_generalize(df_services, 'services')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:45.997972Z","iopub.status.idle":"2023-10-15T04:05:45.998324Z","shell.execute_reply.started":"2023-10-15T04:05:45.998137Z","shell.execute_reply":"2023-10-15T04:05:45.998151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.concat([df_news, df_lifes, df_articles, df_services])","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:45.999085Z","iopub.status.idle":"2023-10-15T04:05:45.999428Z","shell.execute_reply.started":"2023-10-15T04:05:45.999266Z","shell.execute_reply":"2023-10-15T04:05:45.999282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.000314Z","iopub.status.idle":"2023-10-15T04:05:46.000619Z","shell.execute_reply.started":"2023-10-15T04:05:46.000471Z","shell.execute_reply":"2023-10-15T04:05:46.000484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.001369Z","iopub.status.idle":"2023-10-15T04:05:46.001693Z","shell.execute_reply.started":"2023-10-15T04:05:46.001538Z","shell.execute_reply":"2023-10-15T04:05:46.001553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train[df_train['sys_lang'].isin(['en', 'ru', 'qq', 'kk'])]","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.003084Z","iopub.status.idle":"2023-10-15T04:05:46.003586Z","shell.execute_reply.started":"2023-10-15T04:05:46.003339Z","shell.execute_reply":"2023-10-15T04:05:46.003362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def extract_keywords_from_url(url):\n#     url_parts = url.split('/')\n#     keywords = ' '.join(url_parts[3:-1])\n#     return keywords\n# df_train['content'].fillna(df_train['url'].apply(extract_keywords_from_url), inplace=True)\ndf_train['content'] = df_train['content'].apply(lambda x: str(x)[:1465] if len(str(x)) > 1465 else str(x))\ndf_train = df_train.drop_duplicates(subset='url', keep='first')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.005326Z","iopub.status.idle":"2023-10-15T04:05:46.005809Z","shell.execute_reply.started":"2023-10-15T04:05:46.005561Z","shell.execute_reply":"2023-10-15T04:05:46.005584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summary(df):\n    summary_df = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    summary_df['missing#'] = df.isna().sum()\n    summary_df['missing%'] = (df.isna().sum())/len(df)\n    summary_df['uniques'] = df.nunique().values\n    summary_df['count'] = df.count().values\n    return summary_df\n\nsummary(df_train).style.background_gradient(cmap='Greens')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.007501Z","iopub.status.idle":"2023-10-15T04:05:46.007998Z","shell.execute_reply.started":"2023-10-15T04:05:46.007738Z","shell.execute_reply":"2023-10-15T04:05:46.007762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def short_describe(df):\n    rows, cols = df.shape\n    col_names = ', '.join(df.columns.tolist())\n    print(f'* Number of Rows: {rows}')\n    print(f'* Number of Columns: {cols}')\n    print(f'* Column names:\\n {col_names}')\n    \nshort_describe(df_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.009296Z","iopub.status.idle":"2023-10-15T04:05:46.009780Z","shell.execute_reply.started":"2023-10-15T04:05:46.009531Z","shell.execute_reply":"2023-10-15T04:05:46.009554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from spacy.lang.en.stop_words import STOP_WORDS\n\nspacy_nlp = spacy.load('en_core_web_sm')\n\npunctuations = string.punctuation\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\n\ndef spacy_tokenizer(sentence):\n    sentence = re.sub('\\'', '', sentence)\n    sentence = re.sub('\\w*\\d\\w*', '', sentence)\n    sentence = re.sub(' +',' ',sentence)\n    sentence = re.sub(r'\\n: \\'\\'.*','',sentence)\n    sentence = re.sub(r'\\n!.*','',sentence)\n    sentence = re.sub(r'^:\\'\\'.*','',sentence)\n    sentence = re.sub(r'\\n',' ',sentence)\n    sentence = re.sub(r'[^\\w\\s]',' ',sentence)\n    tokens = spacy_nlp(sentence)\n    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n    tokens = [word for word in tokens if word not in stop_words and word not in punctuations and len(word)>2]\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.010874Z","iopub.status.idle":"2023-10-15T04:05:46.011394Z","shell.execute_reply.started":"2023-10-15T04:05:46.011121Z","shell.execute_reply":"2023-10-15T04:05:46.011144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Text Preprocessing & Tokenizing...')\n%time df_train['content_tokenized'] = df_train['content'].map(lambda x: spacy_tokenizer(x))","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.012600Z","iopub.status.idle":"2023-10-15T04:05:46.013094Z","shell.execute_reply.started":"2023-10-15T04:05:46.012834Z","shell.execute_reply":"2023-10-15T04:05:46.012857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.to_csv('tokenized_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.014487Z","iopub.status.idle":"2023-10-15T04:05:46.014988Z","shell.execute_reply.started":"2023-10-15T04:05:46.014725Z","shell.execute_reply":"2023-10-15T04:05:46.014748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.016703Z","iopub.status.idle":"2023-10-15T04:05:46.017244Z","shell.execute_reply.started":"2023-10-15T04:05:46.016954Z","shell.execute_reply":"2023-10-15T04:05:46.016977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_tokenized = df_train['content_tokenized']\ntext = ' '. join(df_train['content_tokenized'].explode())\nwordcloud = WordCloud(background_color='white').generate(text)\nplt.figure(figsize=(15,15), facecolor = None, dpi=300)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.018613Z","iopub.status.idle":"2023-10-15T04:05:46.019136Z","shell.execute_reply.started":"2023-10-15T04:05:46.018850Z","shell.execute_reply":"2023-10-15T04:05:46.018873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stop Words List\nwith open('/kaggle/input/nitec-epir-dataset/stopwords/stopwords-en.txt') as f:\n    en_stoplist = f.read().splitlines()\nwith open('/kaggle/input/nitec-epir-dataset/stopwords/stopwords-ru.txt') as f:\n    ru_stoplist = f.read().splitlines()\nwith open('/kaggle/input/nitec-epir-dataset/stopwords/stopwords-qq.txt') as f:\n    qq_stoplist = f.read().splitlines()\nwith open('/kaggle/input/nitec-epir-dataset/stopwords/stopwords-kk.txt') as f:\n    kk_stoplist = f.read().splitlines()\n\nstoplist = en_stoplist + ru_stoplist + qq_stoplist + kk_stoplist","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.020562Z","iopub.status.idle":"2023-10-15T04:05:46.021059Z","shell.execute_reply.started":"2023-10-15T04:05:46.020793Z","shell.execute_reply":"2023-10-15T04:05:46.020816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim import corpora\n\n# Create Term Dictionary \n%time dictionary = corpora.Dictionary(content_tokenized)\n\nstop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\ndictionary.filter_tokens(stop_ids)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.022329Z","iopub.status.idle":"2023-10-15T04:05:46.023127Z","shell.execute_reply.started":"2023-10-15T04:05:46.022564Z","shell.execute_reply":"2023-10-15T04:05:46.022587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print top 50 items\ndict_tokens = [[[dictionary[key], dictionary.token2id[dictionary[key]]] for key, value in dictionary.items() if key <= 50]]\nprint(dict_tokens)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.024637Z","iopub.status.idle":"2023-10-15T04:05:46.025133Z","shell.execute_reply.started":"2023-10-15T04:05:46.024874Z","shell.execute_reply":"2023-10-15T04:05:46.024908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Extraction\ncorpus = [dictionary.doc2bow(desc) for desc in content_tokenized]\nword_frequencies = [[(dictionary[id], frequency) for id, frequency in line] for line in corpus[0:3]]\nprint(word_frequencies)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.026229Z","iopub.status.idle":"2023-10-15T04:05:46.026716Z","shell.execute_reply.started":"2023-10-15T04:05:46.026469Z","shell.execute_reply":"2023-10-15T04:05:46.026492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build TFIDF and LSI Models\n%time tfidf_model = gensim.models.TfidfModel(corpus, id2word=dictionary)\n%time lsi_model = gensim.models.LsiModel(tfidf_model[corpus], id2word=dictionary, num_topics=300)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.028116Z","iopub.status.idle":"2023-10-15T04:05:46.028625Z","shell.execute_reply.started":"2023-10-15T04:05:46.028375Z","shell.execute_reply":"2023-10-15T04:05:46.028398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Serialize and Store the corpus locallly for easy fetching whenever required\n%time gensim.corpora.MmCorpus.serialize('tfidf_model', tfidf_model[corpus])\n%time gensim.corpora.MmCorpus.serialize('lsi_model', lsi_model[tfidf_model[corpus]])","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.030518Z","iopub.status.idle":"2023-10-15T04:05:46.031024Z","shell.execute_reply.started":"2023-10-15T04:05:46.030755Z","shell.execute_reply":"2023-10-15T04:05:46.030778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the indexed corpus\ntfidf_corpus = gensim.corpora.MmCorpus('tfidf_model')\nlsi_corpus = gensim.corpora.MmCorpus('lsi_model')\n\nprint(tfidf_corpus)\nprint(lsi_corpus)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.032205Z","iopub.status.idle":"2023-10-15T04:05:46.032692Z","shell.execute_reply.started":"2023-10-15T04:05:46.032444Z","shell.execute_reply":"2023-10-15T04:05:46.032468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.similarities import MatrixSimilarity\n\n%time index = MatrixSimilarity(lsi_corpus, num_features = lsi_corpus.num_terms)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.033796Z","iopub.status.idle":"2023-10-15T04:05:46.034297Z","shell.execute_reply.started":"2023-10-15T04:05:46.034034Z","shell.execute_reply":"2023-10-15T04:05:46.034057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from operator import itemgetter\n\ndef search_answer(search_term):\n    query_bow = dictionary.doc2bow(spacy_tokenizer(search_term))\n    query_tfidf = tfidf_model[query_bow]\n    query_lsi = lsi_model[query_tfidf]\n    index.num_best = 5\n    listx = index[query_lsi]\n    listx.sort(key=itemgetter(1), reverse=True)\n    ans = []\n    for i, j in enumerate(listx):\n        ans.append({\n            'accuracy': round((j[1]*100),2),\n            'id': df_train.iloc[j[0]]['id'],\n            'url': df_train.iloc[j[0]]['url'],\n            'category': df_train.iloc[j[0]]['category']\n        })\n        if i == (index.num_best-1):\n            break\n    return pd.DataFrame(ans, columns=['accuracy', 'id', 'url', 'category'])","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.035437Z","iopub.status.idle":"2023-10-15T04:05:46.035929Z","shell.execute_reply.started":"2023-10-15T04:05:46.035671Z","shell.execute_reply":"2023-10-15T04:05:46.035694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing: Example Searching\nans = search_answer('Where can I find the latest updates and information about obtaining public services online in Kazakhstan?')\nans['url'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.037857Z","iopub.status.idle":"2023-10-15T04:05:46.038395Z","shell.execute_reply.started":"2023-10-15T04:05:46.038108Z","shell.execute_reply":"2023-10-15T04:05:46.038133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame(columns=['accuracy', 'id', 'url', 'category'])\n\nfor _, row in df_test.iterrows():\n    result = search_answer(row['question']).iloc[[0]]\n    result.rename(columns={'id': 'index'}, inplace=True)\n    result['id'] = row['id']\n    submission_df = pd.concat([submission_df, result], ignore_index=True)\n\nsubmission_df = submission_df[['id', 'index']]\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T04:05:46.039567Z","iopub.status.idle":"2023-10-15T04:05:46.040085Z","shell.execute_reply.started":"2023-10-15T04:05:46.039815Z","shell.execute_reply":"2023-10-15T04:05:46.039839Z"},"trusted":true},"execution_count":null,"outputs":[]}]}